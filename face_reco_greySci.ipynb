{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9b385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/serengil/deepface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133946af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install deepface\n",
    "# pip install tf-keras\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2 as cv\n",
    "import random\n",
    "import shutil\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6733d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"USERPROFILE\"] = \"G:/grey_sciml/deepface\"  # This works better on Windows\n",
    "os.environ[\"HOME\"] = \"G:/grey_sciml/deepface\"\n",
    "print(\"DeepFace directory:\", os.path.expanduser(\"~/.deepface\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a0c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(r'G:\\grey_sciml\\frame_faces\\dist\\26_Dheeraj_37.jpg')\n",
    "# img = cv.resize(img,(200,250))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d0bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angular distance matrix for image registration\n",
    "def angular_distance(source_representation, test_representation):\n",
    "\n",
    "    # Normalize the vectors\n",
    "    source_normalized = source_representation / np.linalg.norm(source_representation)\n",
    "    test_normalized = test_representation / np.linalg.norm(test_representation)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    cosine_similarity = np.dot(source_normalized, test_normalized)\n",
    "    \n",
    "    # Ensure cosine similarity is within valid range [-1, 1]\n",
    "    cosine_similarity = np.clip(cosine_similarity, -1.0, 1.0)\n",
    "    \n",
    "    # Calculate angular distance\n",
    "    angular_dist = np.arccos(cosine_similarity) / np.pi\n",
    "    \n",
    "    return angular_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370499e0",
   "metadata": {},
   "source": [
    "## Face recogination in Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586bef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_recogination(path):\n",
    "    \n",
    "    fig,ax = plt.subplots(nrows=3,figsize=(6,12))\n",
    "    print(\"path\",path)\n",
    "    name = os.path.splitext(os.path.basename(path))[0]\n",
    "    img = cv.imread(path)\n",
    "    img_rgb = cv.cvtColor(img , cv.COLOR_BGR2RGB)\n",
    "    ax[0].imshow(img_rgb)\n",
    "    ax[0].set_title(f\"original Input Image-{name}\")\n",
    "\n",
    "    detected_face = DeepFace.extract_faces(path, detector_backend='ssd')\n",
    "    x,y,w,h,_,_ = detected_face[0]['facial_area'].values()\n",
    "    x1,y1 = x,y\n",
    "    x2,y2 = x+w,y+h\n",
    "    cv.rectangle(img_rgb,(x1,y1),(x2,y2),(0,0,0),2)\n",
    "    ax[1].imshow(img_rgb)\n",
    "    cropped_img = img[y1:y2, x1:x2]\n",
    "\n",
    "    cv.imwrite(\"Cropped.jpg\",cropped_img )\n",
    "    dfs = DeepFace.find(img_path = r\"G:\\grey_sciml\\Cropped.jpg\",db_path = r\"G:\\grey_sciml\\db\",model_name = \"ArcFace\")\n",
    "    det_path = dfs[0]['identity'][0]\n",
    "    name = os.path.splitext(os.path.basename(det_path))[0]\n",
    "    det_img = cv.imread(det_path)\n",
    "    det_img_rgb = cv.cvtColor(det_img , cv.COLOR_BGR2RGB)\n",
    "    ax[2].imshow(det_img_rgb)\n",
    "    ax[2].set_title(f\"Selected_img-{name}\")\n",
    "\n",
    "\n",
    "face_recogination(r\"db/Alvaro Morte244_235.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e468ab",
   "metadata": {},
   "source": [
    "## Face recogination in in video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604a4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_reco_video(video_path, output_path, db_path):\n",
    "    video = cv.VideoCapture(video_path)       # video_path : path to the video file or 0 for the default camera\n",
    "\n",
    "    fwidth, fheight = int(video.get(cv.CAP_PROP_FRAME_WIDTH)), int(video.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(video.get(cv.CAP_PROP_FPS))    # get the FPS of the video\n",
    "    fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv.VideoWriter(output_path, fourcc, fps, (fwidth, fheight))\n",
    "    frame_count = 0\n",
    "    # print(fps)\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        img_rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        # cv.imshow(\"Frame\",img_rgb)\n",
    "        try:\n",
    "            # face detection\n",
    "            detected_faces = DeepFace.extract_faces(frame, \n",
    "                                                  detector_backend='yolov8',\n",
    "                                                #   enforce_detection=False\n",
    "                                                   )                         \n",
    "\n",
    "            for face in detected_faces:\n",
    "                if face['confidence']>0.7:\n",
    "                    x, y, w, h, _, _ = face['facial_area'].values()\n",
    "                    cv.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "                    cropped_img = frame[y:y+h, x:x+w]\n",
    "                    # temp_path =q \"temp_face.jpg\"\n",
    "                    # cv.imwrite(temp_path, cropped_img)\n",
    "                    amount=1.5\n",
    "                    blurred = cv.GaussianBlur(cropped_img,(5,5),5)\n",
    "                    gray = cv.cvtColor(blurred, cv.COLOR_BGR2GRAY)\n",
    "                    laplacian = cv.Laplacian(gray, cv.CV_64F)\n",
    "                    variance = laplacian.var()\n",
    "                    print(variance)\n",
    "                    if variance>10:\n",
    "                        \n",
    "                        # sharpened = float(amount + 1) * cropped_img - float(amount) * blurred\n",
    "                        # sharpened = np.clip(sharpened, 0, 255).astype(np.uint8)\n",
    "\n",
    "                        # # fig, ax = plt.subplots(nrows =1,ncols=2)\n",
    "                        # sharpened = cv.cvtColor(sharpened,cv.COLOR_BGR2RGB)\n",
    "                        # # sharpened = cv.cvtColor(sharpened,cv.COLOR_BGR2RGB)\n",
    "                        # # out_img = deblur(cropped_img)\n",
    "                        # out_img = cv.cvtColor(sharpened,cv.COLOR_BGR2RGB)\n",
    "                        try:\n",
    "                            # Face recognition\n",
    "                            dfs = DeepFace.find(img_path=cropped_img, \n",
    "                                                db_path=db_path, \n",
    "                                                model_name=\"ArcFace\",\n",
    "                                                #   enforce_detection=False, \n",
    "                                                distance_metric= 'cosine',\n",
    "                                                silent=True\n",
    "                                                )\n",
    "                            # print(dfs)\n",
    "                            # text putting in the frame and showing the result\n",
    "                            if len(dfs) > 0 and len(dfs[0]) > 0:\n",
    "                                det_path = dfs[0]['identity'][0]\n",
    "                                name = det_path.split(\"\\\\\")[3]\n",
    "                                cv.imwrite(f\"G:/grey_sciml/frame_faces/dist/{frame_count}_{name}_{int(variance)}.jpg\",cropped_img)\n",
    "                                cv.putText(frame, f\"frame-{frame_count}\", (10,20 ), cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                                conf = round(1 - dfs[0][\"distance\"][0], 3) \n",
    "                                cv.putText(frame, f\"{name},conf-{conf}\", (x, y - 10), cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                        except:\n",
    "                            print(f\"Not detected_{frame_count}\")\n",
    "                            pass\n",
    "\n",
    "        except:\n",
    "            print(f\"Not recoginised_{frame_count}\")\n",
    "            pass\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "        cv.imshow(\"Face Recognition\", frame)  # Show live result\n",
    "        frame_count += 1\n",
    "        if cv.waitKey(60) & 0xFF == ord('q'):  # Press 'q' to exit\n",
    "            break\n",
    "\n",
    "        # Release resources\n",
    "    video.release()\n",
    "    out.release()\n",
    "    cv.destroyAllWindows()\n",
    "    print(\"completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d446e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_reco_video(\n",
    "    video_path=\"test_dist.mp4\",\n",
    "    output_path=r\"G:\\grey_sciml\\out_dist.mp4\",\n",
    "    db_path=r\"G:\\grey_sciml\\vedio_db\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
