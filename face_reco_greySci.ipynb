{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9b385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/serengil/deepface.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133946af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From g:\\grey_sciml\\env\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pip install deepface\n",
    "# pip install tf-keras\n",
    "\n",
    "import os\n",
    "import cv2 as cv\n",
    "import random\n",
    "import shutil\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from deepface import DeepFace\n",
    "import cv2 as cv\n",
    "from ultralytics import YOLO\n",
    "from deepface import DeepFace\n",
    "# from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2 as cv\n",
    "from ultralytics import YOLO\n",
    "from deepface import DeepFace\n",
    "import numpy as np\n",
    "import os\n",
    "from deep_sort.deep_sort import nn_matching\n",
    "from deep_sort.deep_sort.tracker import Tracker\n",
    "from deep_sort.deep_sort.detection import Detection\n",
    "from deep_sort.application_util import preprocessing,visualization,image_viewer\n",
    "from deep_sort import deep_sort_app\n",
    "from deep_sort import show_results\n",
    "from deep_sort import generate_videos as gdet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6733d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"USERPROFILE\"] = \"G:/grey_sciml/deepface\"  # This works better on Windows\n",
    "os.environ[\"HOME\"] = \"G:/grey_sciml/deepface\"\n",
    "print(\"DeepFace directory:\", os.path.expanduser(\"~/.deepface\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a0c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(r'G:\\grey_sciml\\frame_faces\\dist\\26_Dheeraj_37.jpg')\n",
    "# img = cv.resize(img,(200,250))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d0bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Angular distance matrix for image registration\n",
    "def angular_distance(source_representation, test_representation):\n",
    "\n",
    "    # Normalize the vectors\n",
    "    source_normalized = source_representation / np.linalg.norm(source_representation)\n",
    "    test_normalized = test_representation / np.linalg.norm(test_representation)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    cosine_similarity = np.dot(source_normalized, test_normalized)\n",
    "    \n",
    "    # Ensure cosine similarity is within valid range [-1, 1]\n",
    "    cosine_similarity = np.clip(cosine_similarity, -1.0, 1.0)\n",
    "    \n",
    "    # Calculate angular distance\n",
    "    angular_dist = np.arccos(cosine_similarity) / np.pi\n",
    "    \n",
    "    return angular_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370499e0",
   "metadata": {},
   "source": [
    "## Face recogination in Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586bef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_recogination(path):\n",
    "    \n",
    "    fig,ax = plt.subplots(nrows=3,figsize=(6,12))\n",
    "    print(\"path\",path)\n",
    "    name = os.path.splitext(os.path.basename(path))[0]\n",
    "    img = cv.imread(path)\n",
    "    img_rgb = cv.cvtColor(img , cv.COLOR_BGR2RGB)\n",
    "    ax[0].imshow(img_rgb)\n",
    "    ax[0].set_title(f\"original Input Image-{name}\")\n",
    "\n",
    "    detected_face = DeepFace.extract_faces(path, detector_backend='ssd')\n",
    "    x,y,w,h,_,_ = detected_face[0]['facial_area'].values()\n",
    "    x1,y1 = x,y\n",
    "    x2,y2 = x+w,y+h\n",
    "    cv.rectangle(img_rgb,(x1,y1),(x2,y2),(0,0,0),2)\n",
    "    ax[1].imshow(img_rgb)\n",
    "    cropped_img = img[y1:y2, x1:x2]\n",
    "\n",
    "    cv.imwrite(\"Cropped.jpg\",cropped_img )\n",
    "    dfs = DeepFace.find(img_path = r\"G:\\grey_sciml\\Cropped.jpg\",db_path = r\"G:\\grey_sciml\\db\",model_name = \"ArcFace\")\n",
    "    det_path = dfs[0]['identity'][0]\n",
    "    name = os.path.splitext(os.path.basename(det_path))[0]\n",
    "    det_img = cv.imread(det_path)\n",
    "    det_img_rgb = cv.cvtColor(det_img , cv.COLOR_BGR2RGB)\n",
    "    ax[2].imshow(det_img_rgb)\n",
    "    ax[2].set_title(f\"Selected_img-{name}\")\n",
    "\n",
    "\n",
    "face_recogination(r\"db/Alvaro Morte244_235.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e468ab",
   "metadata": {},
   "source": [
    "## Face recogination in in video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604a4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_reco_video(video_path, output_path, db_path):\n",
    "    video = cv.VideoCapture(video_path)\n",
    "    fwidth, fheight = int(video.get(cv.CAP_PROP_FRAME_WIDTH)), int(video.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(video.get(cv.CAP_PROP_FPS))\n",
    "    fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv.VideoWriter(output_path, fourcc, fps, (fwidth, fheight))\n",
    "    frame_count = 0\n",
    "    # print(fps)\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        img_rgb = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        # cv.imshow(\"Frame\",img_rgb)\n",
    "        try:\n",
    "            detected_faces = DeepFace.extract_faces(frame, \n",
    "                                                  detector_backend='yolov8',\n",
    "                                                  enforce_detection=False\n",
    "                                                   )                         \n",
    "\n",
    "            for face in detected_faces:\n",
    "                if face['confidence']>0.7:\n",
    "                    x, y, w, h, _, _ = face['facial_area'].values()\n",
    "                    cv.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "                    cropped_img = frame[y:y+h, x:x+w]\n",
    "                    cropped_img = cv.resize(cropped_img,(200,250))\n",
    "                    # img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB )\n",
    "                    norm_img = np.zeros((cropped_img.shape[0], img.shape[1]))\n",
    "                    cropped_img = cv.normalize(cropped_img, norm_img, 0, 255, cv.NORM_MINMAX)\n",
    "                    # temp_path =q \"temp_face.jpg\"\n",
    "                    # cv.imwrite(temp_path, cropped_img)\n",
    "                    amount=1.5\n",
    "                    blurred = cv.GaussianBlur(cropped_img,(5,5),5)\n",
    "                    gray = cv.cvtColor(blurred, cv.COLOR_BGR2GRAY)\n",
    "                    laplacian = cv.Laplacian(gray, cv.CV_64F)\n",
    "                    variance = laplacian.var()\n",
    "                    print(variance)\n",
    "                    # if variance>10:\n",
    "                        \n",
    "                    # sharpened = float(amount + 1) * cropped_img - float(amount) * blurred\n",
    "                    # sharpened = np.clip(sharpened, 0, 255).astype(np.uint8)\n",
    "\n",
    "                    # # fig, ax = plt.subplots(nrows =1,ncols=2)\n",
    "                    # sharpened = cv.cvtColor(sharpened,cv.COLOR_BGR2RGB)\n",
    "                    # # sharpened = cv.cvtColor(sharpened,cv.COLOR_BGR2RGB)\n",
    "                    # # out_img = deblur(cropped_img)\n",
    "                    # out_img = cv.cvtColor(sharpened,cv.COLOR_BGR2RGB)\n",
    "                    try:\n",
    "                        dfs = DeepFace.find(img_path=cropped_img, \n",
    "                                            db_path=db_path, \n",
    "                                            model_name=\"ArcFace\",\n",
    "                                            enforce_detection=False, \n",
    "                                            distance_metric= 'cosine',\n",
    "                                            silent=True\n",
    "                                            )\n",
    "                        # print(dfs)\n",
    "                        if len(dfs) > 0 and len(dfs[0]) > 0:\n",
    "                            det_path = dfs[0]['identity'][0]\n",
    "                            name = det_path.split(\"\\\\\")[3]\n",
    "                            cv.imwrite(f\"G:/grey_sciml/frame_faces/dist/{frame_count}_{name}_{int(variance)}.jpg\",cropped_img)\n",
    "                            cv.putText(frame, f\"frame-{frame_count}\", (10,20 ), cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                            conf = round(dfs[0][\"distance\"][0], 3) \n",
    "                            cv.putText(frame, f\"{name},conf-{conf}\", (x, y - 10), cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                    except:\n",
    "                        print(f\"Not detected_{frame_count}\")\n",
    "                        pass\n",
    "\n",
    "        except:\n",
    "            print(f\"Not recoginised_{frame_count}\")\n",
    "            pass\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "        cv.imshow(\"Face Recognition\", frame)  # Show live result\n",
    "        frame_count += 1\n",
    "        if cv.waitKey(60) & 0xFF == ord('q'):  # Press 'q' to exit\n",
    "            break\n",
    "\n",
    "        # Release resources\n",
    "    video.release()\n",
    "    out.release()\n",
    "    cv.destroyAllWindows()\n",
    "    print(\"completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76d446e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not recoginised_0\n",
      "Not recoginised_1\n",
      "Not recoginised_2\n",
      "Not recoginised_3\n",
      "Not recoginised_4\n",
      "Not recoginised_5\n",
      "Not recoginised_6\n",
      "Not recoginised_7\n",
      "Not recoginised_8\n",
      "Not recoginised_9\n",
      "Not recoginised_10\n",
      "Not recoginised_11\n",
      "Not recoginised_12\n",
      "Not recoginised_13\n",
      "Not recoginised_14\n",
      "Not recoginised_15\n",
      "Not recoginised_16\n",
      "Not recoginised_17\n",
      "Not recoginised_18\n",
      "Not recoginised_19\n",
      "Not recoginised_20\n",
      "Not recoginised_21\n",
      "Not recoginised_22\n",
      "Not recoginised_23\n",
      "Not recoginised_24\n",
      "Not recoginised_25\n",
      "Not recoginised_26\n",
      "Not recoginised_27\n",
      "Not recoginised_28\n",
      "Not recoginised_29\n",
      "Not recoginised_30\n",
      "Not recoginised_31\n",
      "Not recoginised_32\n",
      "Not recoginised_33\n",
      "Not recoginised_34\n",
      "Not recoginised_35\n",
      "Not recoginised_36\n",
      "Not recoginised_37\n",
      "Not recoginised_38\n",
      "Not recoginised_39\n",
      "Not recoginised_40\n",
      "Not recoginised_41\n",
      "Not recoginised_42\n",
      "Not recoginised_43\n",
      "Not recoginised_44\n",
      "Not recoginised_45\n",
      "Not recoginised_46\n",
      "Not recoginised_47\n",
      "Not recoginised_48\n",
      "Not recoginised_49\n",
      "Not recoginised_50\n",
      "Not recoginised_51\n",
      "Not recoginised_52\n",
      "Not recoginised_53\n",
      "Not recoginised_54\n",
      "Not recoginised_55\n",
      "Not recoginised_56\n",
      "Not recoginised_57\n",
      "Not recoginised_58\n",
      "Not recoginised_59\n",
      "Not recoginised_60\n",
      "Not recoginised_61\n",
      "Not recoginised_62\n",
      "Not recoginised_63\n",
      "Not recoginised_64\n",
      "Not recoginised_65\n",
      "Not recoginised_66\n",
      "Not recoginised_67\n",
      "Not recoginised_68\n",
      "Not recoginised_69\n",
      "Not recoginised_70\n",
      "Not recoginised_71\n",
      "Not recoginised_72\n",
      "Not recoginised_73\n",
      "Not recoginised_74\n",
      "Not recoginised_75\n",
      "Not recoginised_76\n",
      "Not recoginised_77\n",
      "Not recoginised_78\n",
      "Not recoginised_79\n",
      "Not recoginised_80\n",
      "Not recoginised_81\n",
      "Not recoginised_82\n",
      "Not recoginised_83\n",
      "Not recoginised_84\n",
      "Not recoginised_85\n",
      "Not recoginised_86\n",
      "Not recoginised_87\n",
      "Not recoginised_88\n",
      "Not recoginised_89\n",
      "Not recoginised_90\n",
      "Not recoginised_91\n",
      "Not recoginised_92\n",
      "Not recoginised_93\n",
      "Not recoginised_94\n",
      "Not recoginised_95\n",
      "Not recoginised_96\n",
      "Not recoginised_97\n",
      "Not recoginised_98\n",
      "Not recoginised_99\n",
      "Not recoginised_100\n",
      "Not recoginised_101\n",
      "Not recoginised_102\n",
      "Not recoginised_103\n",
      "Not recoginised_104\n",
      "Not recoginised_105\n",
      "Not recoginised_106\n",
      "Not recoginised_107\n",
      "Not recoginised_108\n",
      "Not recoginised_109\n",
      "Not recoginised_110\n",
      "Not recoginised_111\n",
      "Not recoginised_112\n",
      "Not recoginised_113\n",
      "Not recoginised_114\n",
      "Not recoginised_115\n",
      "Not recoginised_116\n",
      "Not recoginised_117\n",
      "Not recoginised_118\n",
      "Not recoginised_119\n",
      "Not recoginised_120\n",
      "Not recoginised_121\n",
      "Not recoginised_122\n",
      "Not recoginised_123\n",
      "Not recoginised_124\n",
      "Not recoginised_125\n",
      "Not recoginised_126\n",
      "Not recoginised_127\n",
      "Not recoginised_128\n",
      "Not recoginised_129\n",
      "Not recoginised_130\n",
      "Not recoginised_131\n",
      "Not recoginised_132\n",
      "Not recoginised_133\n",
      "Not recoginised_134\n",
      "Not recoginised_135\n",
      "Not recoginised_136\n",
      "Not recoginised_137\n",
      "Not recoginised_138\n",
      "Not recoginised_139\n",
      "Not recoginised_140\n",
      "Not recoginised_141\n",
      "Not recoginised_142\n",
      "Not recoginised_143\n",
      "Not recoginised_144\n",
      "Not recoginised_145\n",
      "Not recoginised_146\n",
      "Not recoginised_147\n",
      "Not recoginised_148\n",
      "Not recoginised_149\n",
      "Not recoginised_150\n",
      "Not recoginised_151\n",
      "Not recoginised_152\n",
      "Not recoginised_153\n",
      "Not recoginised_154\n",
      "Not recoginised_155\n",
      "Not recoginised_156\n",
      "Not recoginised_157\n",
      "Not recoginised_158\n",
      "Not recoginised_159\n",
      "Not recoginised_160\n",
      "Not recoginised_161\n",
      "Not recoginised_162\n",
      "Not recoginised_163\n",
      "Not recoginised_164\n",
      "Not recoginised_165\n",
      "Not recoginised_166\n",
      "Not recoginised_167\n",
      "Not recoginised_168\n",
      "Not recoginised_169\n",
      "Not recoginised_170\n",
      "Not recoginised_171\n",
      "Not recoginised_172\n",
      "Not recoginised_173\n",
      "Not recoginised_174\n",
      "Not recoginised_175\n",
      "Not recoginised_176\n",
      "Not recoginised_177\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "face_reco_video(\n",
    "    video_path=r\"G:\\grey_sciml\\videos\\conference_video.mp4\",\n",
    "    output_path=r\"G:\\grey_sciml\\out_dist.mp4\",\n",
    "    db_path=r\"G:\\grey_sciml\\vedio_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fdc3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_reco_deepsort(video_path, output_path, db_path):\n",
    "    video = cv.VideoCapture(video_path)\n",
    "    fwidth, fheight = int(video.get(cv.CAP_PROP_FRAME_WIDTH)), int(video.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(video.get(cv.CAP_PROP_FPS))\n",
    "    fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv.VideoWriter(output_path, fourcc, fps, (fwidth, fheight))\n",
    "\n",
    "    # Load YOLOv8 (face detector)\n",
    "    detector = YOLO(r\"G:\\grey_sciml\\deepface\\.deepface\\weights\\yolov8n-face.pt\")  # Replace with your model path\n",
    "\n",
    "    # Initialize Deep SORT tracker\n",
    "    max_cosine_distance = 0.3\n",
    "    nn_budget = None\n",
    "    metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n",
    "    tracker = Tracker(metric)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        bboxes, confidences, features = generate_detections(frame, detector, db_path)\n",
    "\n",
    "        detections = [Detection(bbox, conf, feature) for bbox, conf, feature in zip(bboxes, confidences, features)]\n",
    "\n",
    "        # Update tracker\n",
    "        tracker.predict()\n",
    "        tracker.update(detections)\n",
    "\n",
    "        # Draw bounding boxes and track IDs\n",
    "        for track in tracker.tracks:\n",
    "            if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                continue\n",
    "            bbox = track.to_tlwh()\n",
    "            x1, y1, w, h = map(int, bbox)\n",
    "            track_id = track.track_id\n",
    "            cv.rectangle(frame, (x1, y1), (x1 + w, y1 + h), (255, 0, 0), 2)\n",
    "            cv.putText(frame, f\"ID {track_id}\", (x1, y1 - 30), cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
    "\n",
    "        out.write(frame)\n",
    "        cv.imshow(\"Face Recognition + Tracking\", frame)\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    out.release()\n",
    "    cv.destroyAllWindows()\n",
    "    print(\"Completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735f75e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_reco_deepsort(\n",
    "    video_path=r\"G:\\grey_sciml\\videos\\armvd3.mp4\",\n",
    "    output_path=r\"G:\\grey_sciml\\videos\\out_dpsrt.mp4\",\n",
    "    db_path=r\"G:\\grey_sciml\\vedio_db\"\n",
    ")   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
